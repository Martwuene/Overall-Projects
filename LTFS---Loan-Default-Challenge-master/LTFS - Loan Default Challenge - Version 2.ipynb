{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Swetha\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\Swetha\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import KFold   \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_model(model, data, predictors, outcome):\n",
    "  #Fit the model:\n",
    "  model.fit(data[predictors],data[outcome])\n",
    "  \n",
    "  #Make predictions on training set:\n",
    "  predictions = model.predict(data[predictors])\n",
    "  print(predictions)\n",
    "  #Print accuracy\n",
    "  accuracy = metrics.accuracy_score(predictions,data[outcome])\n",
    "  print (\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n",
    "\n",
    "  #Perform k-fold cross-validation with 10 folds\n",
    "  kf = KFold(data.shape[0], n_folds=10)\n",
    "  error = []\n",
    "  for train, test in kf:\n",
    "    # Filter training data\n",
    "    train_predictors = (data[predictors].iloc[train,:])\n",
    "    \n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = data[outcome].iloc[train]\n",
    "    \n",
    "    # Training the algorithm using the predictors and target.\n",
    "    model.fit(train_predictors, train_target)\n",
    "    \n",
    "    #Record error from each cross-validation run\n",
    "    error.append(model.score(data[predictors].iloc[test,:], data[outcome].iloc[test]))\n",
    " \n",
    "  print (\"Cross-Validation Score : %s\" % \"{0:.3%}\".format(np.mean(error)))\n",
    "\n",
    "  #Fit the model again so that it can be refered outside the function:\n",
    "  model.fit(data[predictors],data[outcome]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing\n",
    "\n",
    "dataset['Date.of.Birth']= pd.to_datetime(dataset['Date.of.Birth']) \n",
    "\n",
    "dataset['DisbursalDate']= pd.to_datetime(dataset['DisbursalDate']) \n",
    "\n",
    "dataset = dataset.drop('MobileNo_Avl_Flag', axis = 1)\n",
    "\n",
    "dataset = dataset.drop(['SEC.NO.OF.ACCTS','SEC.ACTIVE.ACCTS','SEC.OVERDUE.ACCTS','SEC.CURRENT.BALANCE','SEC.SANCTIONED.AMOUNT','SEC.DISBURSED.AMOUNT'], axis = 1)\n",
    "\n",
    "dataset['PERFORM_CNS.SCORE.DESCRIPTION'] = dataset['PERFORM_CNS.SCORE.DESCRIPTION'].map({'No Bureau History Available':0, \n",
    "'C-Very Low Risk':1, 'A-Very Low Risk':2, 'D-Very Low Risk':3, 'B-Very Low Risk': 4, 'M-Very High Risk':5, 'F-Low Risk':6, \n",
    "'K-High Risk':7, 'H-Medium Risk':8, 'E-Low Risk':9, 'I-Medium Risk':10, 'G-Low Risk':11, \n",
    "'Not Scored: Sufficient History Not Available': 12, 'J-High Risk':13, 'Not Scored: Not Enough Info available on the customer':14,\n",
    "'Not Scored: No Activity seen on the customer (Inactive)':15, 'Not Scored: No Updates available in last 36 months':16, \n",
    "'L-Very High Risk':17, 'Not Scored: Only a Guarantor':18, 'Not Scored: More than 50 active Accounts found':19})\n",
    "\n",
    "dataset['Employment.Type_random'] = dataset['Employment.Type']\n",
    "random_sample_dataset = dataset['Employment.Type'].dropna().sample(dataset['Employment.Type'].isnull().sum(),random_state = 0)\n",
    "random_sample_dataset.index = dataset[dataset['Employment.Type'].isnull()].index\n",
    "dataset.loc[dataset['Employment.Type'].isnull(), 'Employment.Type_random'] = random_sample_dataset\n",
    "dataset['Employment.Type'] = dataset['Employment.Type_random']\n",
    "dataset = dataset.drop('Employment.Type_random', axis = 1)\n",
    "\n",
    "dataset['Employment.Type'] = dataset['Employment.Type'].map({'Salaried':0, 'Self employed':1})\n",
    "\n",
    "dataset = dataset.drop(['VoterID_flag', 'PRI.DISBURSED.AMOUNT'], axis = 1)\n",
    "\n",
    "index = dataset[(dataset['manufacturer_id'] > 150)].index\n",
    "dataset.drop(index, inplace=True)\n",
    "\n",
    "index = dataset[(dataset['State_ID'] == 22)].index\n",
    "dataset.drop(index, inplace=True)\n",
    "\n",
    "temp = dataset.groupby('PRI.OVERDUE.ACCTS')['PRI.OVERDUE.ACCTS'].count()/np.float(len(dataset))\n",
    "rare_cat = [x for x in temp.loc[temp<0.0005].index.values]\n",
    "dataset['PRI.OVERDUE.ACCTS'] = np.where(dataset['PRI.OVERDUE.ACCTS'].isin(rare_cat), 6 , dataset['PRI.OVERDUE.ACCTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "(0         False\n1         False\n2         False\n3         False\n4         False\n5         False\n6         False\n7         False\n8         False\n9         False\n10        False\n11        False\n12        False\n13        False\n14        False\n15        False\n16        False\n17        False\n18        False\n19        False\n20        False\n21        False\n22        False\n23        False\n24        False\n25        False\n26        False\n27        False\n28        False\n29        False\n          ...  \n233124    False\n233125    False\n233126    False\n233127    False\n233128    False\n233129    False\n233130    False\n233131    False\n233132    False\n233133    False\n233134    False\n233135    False\n233136    False\n233137    False\n233138    False\n233139    False\n233140    False\n233141    False\n233142    False\n233143    False\n233144    False\n233145    False\n233146    False\n233147    False\n233148    False\n233149    False\n233150    False\n233151    False\n233152    False\n233153    False\nName: Employment.Type, Length: 233059, dtype: bool, 'Employment.Type_random')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_setter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1313\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m                     \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3240\u001b[0m             return this.get_indexer(target, method=method, limit=limit,\n\u001b[1;32m-> 3241\u001b[1;33m                                     tolerance=tolerance)\n\u001b[0m\u001b[0;32m   3242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[1;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[0;32m   3258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3259\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_indexer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.lookup\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__hash__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1491\u001b[0m         raise TypeError('{0!r} objects are mutable, thus they cannot be'\n\u001b[1;32m-> 1492\u001b[1;33m                         ' hashed'.format(self.__class__.__name__))\n\u001b[0m\u001b[0;32m   1493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Series' objects are mutable, thus they cannot be hashed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-f5f89ae637de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mrandom_sample_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Employment.Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Employment.Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mrandom_sample_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Employment.Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Employment.Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Employment.Type_random'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_sample_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Employment.Type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Employment.Type_random'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Employment.Type_random'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    178\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'cannot do'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexingError\u001b[0m: (0         False\n1         False\n2         False\n3         False\n4         False\n5         False\n6         False\n7         False\n8         False\n9         False\n10        False\n11        False\n12        False\n13        False\n14        False\n15        False\n16        False\n17        False\n18        False\n19        False\n20        False\n21        False\n22        False\n23        False\n24        False\n25        False\n26        False\n27        False\n28        False\n29        False\n          ...  \n233124    False\n233125    False\n233126    False\n233127    False\n233128    False\n233129    False\n233130    False\n233131    False\n233132    False\n233133    False\n233134    False\n233135    False\n233136    False\n233137    False\n233138    False\n233139    False\n233140    False\n233141    False\n233142    False\n233143    False\n233144    False\n233145    False\n233146    False\n233147    False\n233148    False\n233149    False\n233150    False\n233151    False\n233152    False\n233153    False\nName: Employment.Type, Length: 233059, dtype: bool, 'Employment.Type_random')"
     ]
    }
   ],
   "source": [
    "#Pre-processing\n",
    "\n",
    "test['Date.of.Birth']= pd.to_datetime(test['Date.of.Birth']) \n",
    "\n",
    "test['DisbursalDate']= pd.to_datetime(test['DisbursalDate']) \n",
    "\n",
    "test = test.drop('MobileNo_Avl_Flag', axis = 1)\n",
    "\n",
    "test = test.drop(['SEC.NO.OF.ACCTS','SEC.ACTIVE.ACCTS','SEC.OVERDUE.ACCTS','SEC.CURRENT.BALANCE','SEC.SANCTIONED.AMOUNT','SEC.DISBURSED.AMOUNT'], axis = 1)\n",
    "\n",
    "test['PERFORM_CNS.SCORE.DESCRIPTION'] = test['PERFORM_CNS.SCORE.DESCRIPTION'].map({'No Bureau History Available':0, \n",
    "'C-Very Low Risk':1, 'A-Very Low Risk':2, 'D-Very Low Risk':3, 'B-Very Low Risk': 4, 'M-Very High Risk':5, 'F-Low Risk':6, \n",
    "'K-High Risk':7, 'H-Medium Risk':8, 'E-Low Risk':9, 'I-Medium Risk':10, 'G-Low Risk':11, \n",
    "'Not Scored: Sufficient History Not Available': 12, 'J-High Risk':13, 'Not Scored: Not Enough Info available on the customer':14,\n",
    "'Not Scored: No Activity seen on the customer (Inactive)':15, 'Not Scored: No Updates available in last 36 months':16, \n",
    "'L-Very High Risk':17, 'Not Scored: Only a Guarantor':18, 'Not Scored: More than 50 active Accounts found':19})\n",
    "\n",
    "test['Employment.Type_random'] = test['Employment.Type']\n",
    "random_sample_test = test['Employment.Type'].dropna().sample(test['Employment.Type'].isnull().sum(),random_state = 0)\n",
    "random_sample_test.index = test[test['Employment.Type'].isnull()].index\n",
    "test.loc[dataset['Employment.Type'].isnull(), 'Employment.Type_random'] = random_sample_test\n",
    "test['Employment.Type'] = test['Employment.Type_random']\n",
    "test = test.drop('Employment.Type_random', axis = 1)\n",
    "\n",
    "test['Employment.Type'] = test['Employment.Type'].map({'Salaried':0, 'Self employed':1})\n",
    "\n",
    "test = test.drop(['VoterID_flag', 'PRI.DISBURSED.AMOUNT'], axis = 1)\n",
    "\n",
    "index = test[(test['manufacturer_id'] > 150)].index\n",
    "test.drop(index, inplace=True)\n",
    "\n",
    "index = test[(test['State_ID'] == 22)].index\n",
    "test.drop(index, inplace=True)\n",
    "\n",
    "temp = test.groupby('PRI.OVERDUE.ACCTS')['PRI.OVERDUE.ACCTS'].count()/np.float(len(test))\n",
    "rare_cat = [x for x in temp.loc[temp<0.0005].index.values]\n",
    "test['PRI.OVERDUE.ACCTS'] = np.where(test['PRI.OVERDUE.ACCTS'].isin(rare_cat), 6 , test['PRI.OVERDUE.ACCTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop(['PAN_flag','Driving_flag'], axis = 1)\n",
    "index = dataset[(dataset['manufacturer_id'] > 150)].index\n",
    "dataset.drop(index, inplace=True)\n",
    "index = dataset[(dataset['State_ID'] == 22)].index\n",
    "dataset.drop(index, inplace=True)\n",
    "\n",
    "temp = dataset.groupby('PRI.OVERDUE.ACCTS')['PRI.OVERDUE.ACCTS'].count()/np.float(len(dataset))\n",
    "rare_cat = [x for x in temp.loc[temp<0.0005].index.values]\n",
    "dataset['PRI.OVERDUE.ACCTS'] = np.where(dataset['PRI.OVERDUE.ACCTS'].isin(rare_cat), 6 , dataset['PRI.OVERDUE.ACCTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = dataset.drop(['PAN_flag','Driving_flag'], axis = 1)\n",
    "index = dataset[(dataset['manufacturer_id'] > 150)].index\n",
    "dataset.drop(index, inplace=True)\n",
    "index = dataset[(dataset['State_ID'] == 22)].index\n",
    "dataset.drop(index, inplace=True)\n",
    "\n",
    "temp = dataset.groupby('PRI.OVERDUE.ACCTS')['PRI.OVERDUE.ACCTS'].count()/np.float(len(dataset))\n",
    "rare_cat = [x for x in temp.loc[temp<0.0005].index.values]\n",
    "dataset['PRI.OVERDUE.ACCTS'] = np.where(dataset['PRI.OVERDUE.ACCTS'].isin(rare_cat), 6 , dataset['PRI.OVERDUE.ACCTS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 78.367%\n",
      "Cross-Validation Score : 78.295%\n"
     ]
    }
   ],
   "source": [
    "outcome_var = 'loan_default'\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "predictor_var = ['disbursed_amount', 'asset_cost', 'ltv', 'branch_id',\n",
    "       'supplier_id', 'manufacturer_id', 'Current_pincode_ID',\n",
    "       'Employment.Type', 'State_ID', 'Employee_code_ID',\n",
    "       'Aadhar_flag', 'Passport_flag', 'PERFORM_CNS.SCORE',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION', 'PRI.NO.OF.ACCTS', 'PRI.ACTIVE.ACCTS',\n",
    "       'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE', 'PRI.SANCTIONED.AMOUNT',\n",
    "       'PRIMARY.INSTAL.AMT', 'SEC.INSTAL.AMT', 'NEW.ACCTS.IN.LAST.SIX.MONTHS',\n",
    "       'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS', 'AVERAGE.ACCT.AGE',\n",
    "       'CREDIT.HISTORY.LENGTH', 'NO.OF_INQUIRIES']\n",
    "classification_model(model, dataset ,predictor_var,outcome_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-7cd838659c94>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m        'CREDIT.HISTORY.LENGTH', 'NO.OF_INQUIRIES']\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictor_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictor_var\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    536\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \"\"\"\n\u001b[1;32m--> 576\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimators_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    766\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "outcome_var = 'loan_default'\n",
    "predictor_var = ['disbursed_amount', 'asset_cost', 'ltv', 'branch_id',\n",
    "       'supplier_id', 'manufacturer_id', 'Current_pincode_ID',\n",
    "       'Employment.Type', 'State_ID', 'Employee_code_ID',\n",
    "       'Aadhar_flag', 'Passport_flag', 'PERFORM_CNS.SCORE',\n",
    "       'PERFORM_CNS.SCORE.DESCRIPTION', 'PRI.NO.OF.ACCTS', 'PRI.ACTIVE.ACCTS',\n",
    "       'PRI.OVERDUE.ACCTS', 'PRI.CURRENT.BALANCE', 'PRI.SANCTIONED.AMOUNT',\n",
    "       'PRIMARY.INSTAL.AMT', 'SEC.INSTAL.AMT', 'NEW.ACCTS.IN.LAST.SIX.MONTHS',\n",
    "       'DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS', 'AVERAGE.ACCT.AGE',\n",
    "       'CREDIT.HISTORY.LENGTH', 'NO.OF_INQUIRIES']\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=10)\n",
    "model.fit(dataset[predictor_var],dataset[outcome_var])\n",
    "predictions = model.predict(dataset[predictor_var])\n",
    "dataset['predictions'] = predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueID</th>\n",
       "      <th>disbursed_amount</th>\n",
       "      <th>asset_cost</th>\n",
       "      <th>ltv</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>manufacturer_id</th>\n",
       "      <th>Current_pincode_ID</th>\n",
       "      <th>Date.of.Birth</th>\n",
       "      <th>Employment.Type</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI.SANCTIONED.AMOUNT</th>\n",
       "      <th>PRIMARY.INSTAL.AMT</th>\n",
       "      <th>SEC.INSTAL.AMT</th>\n",
       "      <th>NEW.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS</th>\n",
       "      <th>AVERAGE.ACCT.AGE</th>\n",
       "      <th>CREDIT.HISTORY.LENGTH</th>\n",
       "      <th>NO.OF_INQUIRIES</th>\n",
       "      <th>loan_default</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420825</td>\n",
       "      <td>50578</td>\n",
       "      <td>58400</td>\n",
       "      <td>89.55</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1441</td>\n",
       "      <td>1984-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>537409</td>\n",
       "      <td>47145</td>\n",
       "      <td>65550</td>\n",
       "      <td>73.23</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1502</td>\n",
       "      <td>1985-07-31</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>50200</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>417566</td>\n",
       "      <td>53278</td>\n",
       "      <td>61360</td>\n",
       "      <td>89.63</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1497</td>\n",
       "      <td>1985-08-24</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>624493</td>\n",
       "      <td>57513</td>\n",
       "      <td>66113</td>\n",
       "      <td>88.48</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1501</td>\n",
       "      <td>1993-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539055</td>\n",
       "      <td>52378</td>\n",
       "      <td>60300</td>\n",
       "      <td>88.39</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1495</td>\n",
       "      <td>1977-09-12</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UniqueID  disbursed_amount  asset_cost    ltv  branch_id  supplier_id  \\\n",
       "0    420825             50578       58400  89.55         67        22807   \n",
       "1    537409             47145       65550  73.23         67        22807   \n",
       "2    417566             53278       61360  89.63         67        22807   \n",
       "3    624493             57513       66113  88.48         67        22807   \n",
       "4    539055             52378       60300  88.39         67        22807   \n",
       "\n",
       "   manufacturer_id  Current_pincode_ID Date.of.Birth  Employment.Type  \\\n",
       "0               45                1441    1984-01-01                0   \n",
       "1               45                1502    1985-07-31                1   \n",
       "2               45                1497    1985-08-24                1   \n",
       "3               45                1501    1993-12-30                1   \n",
       "4               45                1495    1977-09-12                1   \n",
       "\n",
       "      ...      PRI.SANCTIONED.AMOUNT  PRIMARY.INSTAL.AMT  SEC.INSTAL.AMT  \\\n",
       "0     ...                          0                   0               0   \n",
       "1     ...                      50200                1991               0   \n",
       "2     ...                          0                   0               0   \n",
       "3     ...                          0                  31               0   \n",
       "4     ...                          0                   0               0   \n",
       "\n",
       "   NEW.ACCTS.IN.LAST.SIX.MONTHS  DELINQUENT.ACCTS.IN.LAST.SIX.MONTHS  \\\n",
       "0                             0                                    0   \n",
       "1                             0                                    1   \n",
       "2                             0                                    0   \n",
       "3                             0                                    0   \n",
       "4                             0                                    0   \n",
       "\n",
       "   AVERAGE.ACCT.AGE  CREDIT.HISTORY.LENGTH  NO.OF_INQUIRIES  loan_default  \\\n",
       "0                 0                      0                0             0   \n",
       "1                23                     23                0             1   \n",
       "2                 0                      0                0             0   \n",
       "3                 8                     15                1             1   \n",
       "4                 0                      0                1             1   \n",
       "\n",
       "   predictions  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
